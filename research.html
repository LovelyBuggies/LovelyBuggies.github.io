<!DOCTYPE html>
<head>
    <link rel="stylesheet" href="./styles/index.css" type="text/css" />
</head>

<body>
    <div id="layout-content">
        
        <script src="styles/head.js"></script>

        <h2>Decentralized LLM Collaboration with Multi-Agent Reinforcement Learning</h2>
        <p>
            Decentralized LLM collaboration offers great benefits by allowing specialized LLMs to divide and conquer complex problems and operate in parallel to improve efficiency. We develop a cooperative multi-agent reinforcement learning training framework that enables decentralized LLM agents to coordinate effectively, achieving equal or better performance than a single larger LLM [<a href="https://arxiv.org/abs/2508.04652">ref1</a>], [<a href="https://arxiv.org/pdf/2601.21972">ref2</a>].

        </p>

        <h2>Mean-Field Game for Autonomous Vehicles Navigation</h2>
        
        <p>
            Mean-Field Game is developed to study the decision-making strategy in multi-agent systems with very large populations by building a connection between stochastic modeling and distributed control. In the context of autonomous vehicle navigation, each vehicle acts as an agent and makes decisions regarding velocity control and route choice [<a href="https://www.researchgate.net/publication/372391123_Learning_Dual_Mean_Field_Games_on_Graphs">ref</a>] according to current population density distribution. The actions of all vehicles jointly trigger the evolution of density dynamics. This process repeats until it converges to the mean-field equilibrium. We proposed various approaches to address the practical challenges, such as fine granularity [<a href="https://dl.acm.org/doi/abs/10.5555/3545946.3598748">ref</a>], scalability and computational efficiency [<a href="https://www.mdpi.com/2227-7390/12/6/803">ref1</a>, <a href="https://www.mdpi.com/2073-4336/15/2/12">ref2</a>].<br><br>

            <img src="./imgs/research/mfg.png" width="600" style="border: 1px solid #555;"></i><br><br>
        </p>
        
        </div>
</body>
</html>
